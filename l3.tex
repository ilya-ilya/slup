




\section{Лекция от 22.02.17.
Пуассоновские процессы}


\subsection{Процессы восстановления (продолжение)}

\begin{df}
	Будем говорить, что дискретная случайная величина $U$ имеет \index{Распределение!геометрическое}\textit{геометрическое распределение} с параметром $p \in (0, 1)$, если для $k = 0, 1, 2\etc$ $\Pb(U = k) = (1-p)^{k}p$.
\end{df}

\begin{lemma}\label{lemsum}
	\sloppy
	Рассмотрим независимые геометрические величины $U_{0}\etc , U_{j}$ с параметром $p \in (0, 1)$, где $j = \left[ \frac{t}{\alpha} \right]$.
Тогда
	$$
		\Pb (j + U_{0} + \ldots + U_{j} = m) = \Pb (Z^{\star}(t) = m ).
	$$
\end{lemma}

\begin{proof}
	 Обозначим $M = \left\{ (k_0\etc, k_j)\colon k_j \in \nonneg, \sum\limits_{i = 0}^j k_j = m - j\right\}$.
	\begin{multline*}
		\Pb\left( U_0 + \ldots + U_j = m - j\right) = \sum_{(k_0\etc, k_j) \in M} \Pb(U_0 = k_0\etc, U_j = k_j) =\\
		= \sum_{(k_0\etc, k_j) \in M} \Pb(U_0 = k_0)\ldots \Pb(U_j = k_j) = \sum_{(k_0\etc, k_j) \in M} p (1 - p)^{k_0}\ldots p (1 - p)^{k_j} =\\
		= \sum_{(k_0\etc, k_j) \in M} = p^{j + 1} (1 - p)^{k_0 + \ldots + k_j} =\\
		= p^{j + 1} (1 - p)^{m - j} \#M = C_m^j p^{j + 1} (1 - p)^{m - j}.
	\end{multline*}
\end{proof}

\subsection{Сопоставление исходного процесса восстановления со вспомогательным}

\begin{lemma}\label{est}
	Пусть $t \ge \alpha$.
Тогда $\Ef Z^\star(t) \le At$ и $\Ef Z^\star(t)^2 \le B t^2$, где $A = A(p, \alpha) > 0$, $B = B(p, \alpha) > 0$.
\end{lemma}

\begin{proof}
	По лемме \ref{lemsum} $\Ef Z^\star(t) = \Ef(j + U_0 + \ldots + U_j) = j + (j + 1) \Ef U$, где $\Ef U =: a(p) < \bes$ "\td математическое ожидание геометрического распределения.

	Тогда
	\begin{multline*}
		\Ef Z^\star(t) = j + (j + 1) a(p) \le (j + 1) \big(a(p) + 1\big) \le\\
		\le \frac{t + \alpha}{\alpha} \big(a(p) + 1\big) \le \frac{2 t}{\alpha} \big( a(p) + 1 \big) = A t,
	\end{multline*}
	где $A \deq \frac{2 (a(p) + 1)}{\alpha}$.

	Далее,
	\begin{multline*}
		\Ef Z^\star(t)^2 = \var Z^\star(t) + \big(\Ef Z^\star(t) \big)^2 \le (j + 1) \underbrace{\var U}_{\sigma^2(p)} + (j + 1)^2 \big( a(p) + 1 \big)^2 \le\\
		\le (j + 1)^2 \left( \sigma^2(p) + \big( a(p) + 1 \big)^2 \right) \le \frac{4}{\alpha^2} \left( \sigma^2(p) + \big( a(p) + 1 \big)^2 \right) t^2 = B t^2,
	\end{multline*}
	где $B \deq \frac{4}{\alpha^2} \left( \sigma^2(p) + \big( a(p) + 1 \big)^2 \right)$.
\end{proof}

Заметим, что для любой невырожденной (не равной константе почти наверное) случайной величины $X \ge 0$ найдется такое $\alpha > 0$, что $\Pb(X > \alpha) = p \in (0, 1)$.
Тогда построим процесс $Z^\star$, как в определении \ref{dfstar}, по независимым одинаково распределенным случайным величинам
$$
	Y_n =
	\begin{cases}
		\alpha, &\text{если }X_n > \alpha,\\
		0, &\text{если }X_n \le \alpha.
	\end{cases}
$$

По построению $Y_n \le X_n$, откуда $Z(t) \le Z^\star(t)$, $t \ge 0$.

\begin{cor}
	$\Ef Z(t) \le A t$ и $\Ef Z(t)^2 \le B t^2$ для любого $t \ge \alpha$.
В частности, $Z(t) < \bes$ п.\,н.
при всех $t \ge 0$.
\end{cor}

\begin{cor}
	$\Pb\left( \forall\, t \ge 0\; Z(t) < \bes \right) = 1$.
\end{cor}

\begin{proof}
	Поскольку $Z(t)$ является неубывающим процессом, т.\,е.
$\forall\, s \le t \; Z(s) \le Z(t)$, то достаточно доказать, что $\Pb\left(\forall\,n \in \N\; Z(n) < \bes\right) = 1$.
Но
	$$
		\left\{ \forall\,n \in \N\; Z(n) < \bes \right\} = \bigcap_{n \in \N} \left\{ Z(n) < \bes \right\} \text{"\td}
	$$
	счетное пересечение событий вероятности 1 (см.
предыдущее следствие).
Оно тоже имеет вероятность 1.
\end{proof}


\subsection{Элементарная теория восстановления}

\begin{lemma}
	Пусть $X, X_1, X_2\etc$	"\td н.\,о.\,р.
случайные величины, $X \ge 0$.
Тогда $\frac{S_n}{n} \as \mu \in [0, \bes]$ при $n \to \bes$, где $\mu = \Ef X$ (конечное или бесконечное).
\end{lemma}

\begin{proof}
	Если $\mu < \bes$, то утверждение леммы представляет собой усиленный закон больших чисел А.\,Н.\,Колмогорова.

	Пусть $\mu = \bes$.
Положим для $c > 0$
	$$
		V_n(c) \deq X_n \ind\left\{X_n \le c\right\}.
	$$
	Тогда снова по УЗБЧ А.\,Н.\,Колмогорова $\frac{1}{n} \sum\limits_{k = 1}^n V_k \as \Ef X \ind\left\{X_n \le c\right\}$.

	Возьмем $c = m \in \N$.
Тогда с вероятностью 1
	$$
		\liminf_{n\to \bes} \frac{1}{n}\sum_{k = 1}^n X_k \ge \lim_{m \to \bes} \Ef X \ind\left\{X \le m\right\} = \Ef X.
	$$
	В последнем равенстве использовалась теорема о монотонной сходимости (для бесконечного предельного интеграла).
\end{proof}

Введем определение, которое понадобится нам в дальнейшем.

\begin{df}
	Семейство случайных величин $\left\{ \xi_\alpha, t \in \Lambda \right\}$ называется \textit{равномерно интегрируемым}, если
	$$
		\lim_{c \to \bes} \sup_{\alpha \in \Lambda} \int_{ \left\{ |\xi_\alpha| \ge c \right\}} |\xi_\alpha| \dif\Pb = 0.
	$$
\end{df}

Известно, что если семейство $\left\{ \xi_n, n \ge 1\right\}$ равномерно интегрируемо и $\xi_n \to \xi$ почти наверное, то $\xi$ тоже интегрируема и $\Ef \xi_n \to \Ef \xi$.
Для неотрицательных случайных величин $\xi_n$, $n \ge 1$, таких, что $\xi_n \to \xi$ п.\,н., где $\Ef \xi < \bes$, имеет место и обратная импликация
$$
	\Ef \xi_n \to \Ef \xi\; \Longto\; \text{семейство $\left\{ \xi_n, n \ge 1 \right\}$ равномерно интегрируемо.}
$$

Следующая теорема принимается без доказательства
\begin{theorem}[Де ла Валле Пуссен]\index{Теорема!Де ла Валле Пуссена}\label{pussen}
	\sloppy
	Семейство случайных величин $\left\{ \xi_\alpha, \alpha \in \Lambda\right\}$ является равномерно интегрируемым тогда и только тогда, когда найдется измеримая функция $g\colon \real_+ \to \real_+$, т.\,е.
$g \in \borel(\real_+) | \borel(\real_+)$, такая, что
	$$
		\lim_{t \to \bes}\frac{g(t)}{t} = \bes\quad \text{и}\quad \sup \Ef g(|\xi_\alpha|) < \bes.
	$$
\end{theorem}

\begin{theorem}
	Пусть $Z = \left\{ Z(t), t\ge 0 \right\}$ "\td процесс восстановления, построенный по последовательности н.\,о.\,р случайных величин $X, X_1, X_2\etc$ .
Тогда
	\begin{enumerate}
		\item\label{firstel} $\displaystyle \frac{Z(t)}{t} \as \frac{1}{\mu}$ при $t \to \bes$;
		\item\label{secondel} $\displaystyle \frac{\Ef Z(t)}{t} \to \frac{1}{\mu}$ при $t \to \bes$, где $\frac{1}{0} \deq \bes$, $\frac{1}{\bes} \deq 0$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Если $\mu = 0$, то $X_n = 0$ п.\,н., поэтому $\forall\, t > 0 \; Z(t) = \bes$ и утверждение теоремы очевидно.

	Далее $\mu > 0$.
Заметим, что
	$$
		S_{Z(t)} \le t < S_{Z(t) + 1}
		\label{eqz}
	$$
	Для фиксированного $\omega$ рассмотрим последовательность $t_n \deq S_n(\omega)$.
Поскольку $Z(t_n, \omega) = n$ и траектория $Z(t, \omega)$ монотонна, $Z(t, \omega) \to \bes$.
Будем рассматривать те $(t, \omega)$, для которых $0 < Z(t, \omega) < \bes$ (при всех $t_n$, а значит, вообще при всех $t$ это выполнено почти наверное).
Для этих $(t, \omega)$ разделим обе части \ref{eqz} на $Z(t)$.
Получим
	$$
		\frac{S_{Z(t)}}{Z(t)} \le \frac{t}{Z(t)} < \frac{S_{Z(t) + 1}}{Z(t) + 1}\frac{Z(t) + 1}{Z(t)}.
	$$
	Но поскольку $Z(t) \to \bes$, то $\frac{S_{Z(t)}}{Z(t)} \as \mu$, $\frac{S_{Z(t) + 1}}{Z(t) + 1} \as \mu$ и $\frac{Z(t) + 1}{Z(t)} \to 1$.
Следовательно, $\frac{t}{Z(t)} \as \mu$ при $t \to \bes$, т.\,е.
$\frac{Z(t)}{t} \as \frac{1}{\mu}$, что завершает доказательство утверждения \ref{firstel}.

	Для доказательства утверждения \ref{secondel} используем теорему \ref{pussen}.
А именно, рассмотрим семейство $\left\{\xi_t, t \ge \alpha\right\}$ и функцию $g(t) = t^2$, где $\xi_t = \frac{Z(t)}{t}$.
По лемме \ref{est}
	$$
		\Ef \xi_t^2 = \frac{\Ef Z(t)^2}{t^2} \le \frac{B t^2}{t^2} = B < \bes.
	$$
	Все условия теоремы \ref{pussen} выполнены.
Поэтому из нее вытекает, что семейство $\left\{\xi_t, t \ge \alpha\right\}$ равномерно интегрируемо.
Тогда можно совершить предельный переход под знаком математического ожидания, и из утверждения \ref{firstel} получаем, что
	$$
		\Ef \frac{Z(t)}{t} \to \Ef \frac{1}{\mu} = \frac{1}{\mu},\quad t \to \bes.
	$$
\end{proof}


\subsection{Пуассоновский процесс как процесс восстановления}

\begin{df}
	\sloppy
	Пусть $X$, $X_1$, $X_2$\etc	"\td независимые одинаково распределенные случайные величины с экспоненциальным распределением $X\sim \Exp(\lambda)$, т.\,е.
	$$
		p_X(x) =
		\begin{cases}
			\lambda e^{- \lambda x}, &\text{если $x \ge 0$,}\\
			0, &\text{если $x < 0$}.
		\end{cases}
	$$
	\textit{Пуассоновским процессом}\index{Процесс!пуассоновский}\index{Пуассоновский процесс} $N = \left\{N(t), t\ge 0\right\}$ называется процесс восстановления, построенный по $X_1$, $X_2$\etc.
\end{df}

Для $t > 0$ введем случайные величины
\begin{align*}
	X_1^t &\deq S_{N(t) + 1} - t;\\
	X_k^t &\deq S_{N(t) + k},\quad k \ge 2.
\end{align*}

\begin{lemma}
	\sloppy
	Для любого $t > 0$ случайные величины $N(t)$, $X_1^t$, $X_2^t$\etc являются независимыми, причем $N(t) \sim \Pois(\lambda t)$, $X_k^t \sim \Exp(\lambda)$ для $k = 1, 2\etc$.
\end{lemma}

\begin{proof}
	Чтобы доказать независимость указанных случайных величин, достаточно проверить, что для $\forall\, n \in \nonneg\; \forall\,u_1\etc, u_k \ge 0$ выполнено
	$$
		\Pb(N(t) = n, X_1^t > u_1\etc, X_k^t > u_k) = \Pb(N(t) = n) \Pb(X_1^t > u_1) \ldots \Pb(X_k^t > u_k).
	$$

	Доказываем это индукцией по $k$.

	База индукции: $k = 1$.
Напомним (было в курсе теории вероятностей), что случайная величина $S_n$ имеет плотность
	$$
		p_{S_n}(x) =
		\begin{cases}
			\frac{\lambda (\lambda x)^{n - 1}}{(n - 1)!} e^{- \lambda x}, &\text{если $x \ge 0$};\\
			0, &\text{если $x < 0$}.
		\end{cases}
	$$

	Итак,
	\begin{multline*}
		\Pb(N(t) = n, X_1^t > u_1) = \Pb(S_n \le t, S_{n + 1} > t, S_{N(t) + 1} - t > u_1) =\\
		= \Pb(S_n \le t, S_{n + 1} > t, S_{n + 1} > t + u_1) = \Pb(S_n \le t, S_{n + 1} > t + u_1) =\\
		= \Pb(S_n \le t, S_n + X_{n + 1} > t + u_1) =\\
		= \Pb\left((S_n, X_{n + 1}) \in \left\{(x, y)\colon x \le t, x + y > t + u_1\right\} \right) =\\
		\iint\limits_{\substack{x \le t\\ x + y > t + u_1}} p_{(S_n, X_{n + 1})}(x, y) \dif x \dif y = \left(\text{независимость $S_n$ и $X_{n + 1}$}\right) =\\
		= \iint\limits_{\substack{x \le t\\ x + y > t + u_1}} p_{S_n}(x) p_{X_{n + 1}}(y) \dif x \dif y = \iint\limits_{\substack{0 \le x \le t, y \ge 0\\ x + y > t + u_1}} \frac{\lambda (\lambda x)^{n - 1}}{(n - 1)!} e^{- \lambda x} \lambda e^{-\lambda y} \dif x \dif y =\\
		= \left(\text{теорема Фубини}\right) = \int\limits_{0}^{t} \frac{\lambda (\lambda x)^{n - 1}}{(n - 1)!} e^{- \lambda x} \dif x \int\limits_{t + u_1 - x}^{+\bes} \lambda	e^{-\lambda y} \dif y =\\
		= \int\limits_{0}^{t} \frac{\lambda (\lambda x)^{n - 1}}{(n - 1)!} e^{- \lambda x} e^{-\lambda (t + u_1 - x)} \dif x = e^{-\lambda (t + u_1)} \int\limits_{0}^{t} \frac{\lambda (\lambda x)^{n - 1}}{(n - 1)!} \dif x =\\
		= \frac{(\lambda t)^n}{n!} e^{-\lambda t} e^{-\lambda u_1}.
	\end{multline*}

	Положим $u_1 = 0$, получим
	$$
		\Pb(N(t) = n, X_1^t > 0) = \Pb(N(t) = n) = \frac{(\lambda t)^n}{n!} e^{-\lambda t},\quad n\in \nonneg,
	$$
	т.\,е.
$N(t) \sim \Pois(\lambda t)$.
Далее,
	$$
		\Pb(X_1^t > u_1) = \sum_{n = 0}^\bes \Pb(N(t) = n, X_1^t > u_1) = \sum_{n = 0}^\bes \frac{(\lambda t)^n}{n!} e^{-\lambda t} \cdot e^{-\lambda u_1} = 1\cdot e^{-\lambda u_1},
	$$
	т.\,е.
$X_1^t \sim \Exp(\lambda)$ и база установлена.

	Индукционный переход: пусть $k \ge 2$.
	\begin{multline*}
		\Pb(N(t) = n, X_1^t > u_1\etc, X_k^t > u_k) =\\ \Pb(S_n \le t, S_{n + 1} > t, S_{n + 1} > t + u_1, X_{n + 2} > u_2\etc, X_{n + k} > u_k) =\\
		= \left(\text{см.
предыдущее}\right) = \Pb(N(t) = n) \Pb(X_1^t > u_1) e^{-\lambda u_2} \ldots e^{-\lambda u_k} =\\
		= \Pb(N(t) = n)	e^{-\lambda u_1} \ldots e^{-\lambda u_k}.
	\end{multline*}

	Снова положим $u_1 = \ldots = u_{k - 1} = 0$ и просуммируем по всем $n \in \nonneg$.
Получим $\Pb(X_k^t > u_k) = e^{-\lambda u_k}$, откуда $X_k^t \sim \Exp(\lambda)$, индукционный переход завершен.
\end{proof}

Пусть $X_j \sim \Exp(\lambda)$ "\td интервалы между временами прихода автобусов на данную остановку.
Тогда случайная величина $X_1^t = S_{N(t) + 1} - t$ соответствует времени ожидания прибытия ближайшего автобуса.
Мы только что доказали, что она распределена так же, как и интервалы: $X_1^t \sim \Exp(\lambda)$.
Мы будем в среднем ждать автобуса столько же времени, сколько в среднем проходит времени между двумя автобусами.
В этом состоит \textbf{парадокс времени ожидания}\index{Парадокс времени ожидания}.
Никакого противоречия здесь на самом деле нет, так как сами моменты прихода автобусов также случайные.

\clearpage
\phantomsection
\addcontentsline{toc}{section}{Предметный указатель}
\printindex

